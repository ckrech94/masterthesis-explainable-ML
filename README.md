# Explainable Machine Learning - Feature Engineering with Black-Box-Models: 
### Original: Erkl√§rbarkeit maschineller Lernverfahren - Feature Engineering mit Black-Box-Modellen
This master thesis was written as part of the Data Science master's program at Darmstadt University of Applied Sciences, Germany, in cooperation with the financial services provider Arvato Financial Solutions.

This repository provides the code for generating the models and graphics used in the thesis. Furthermore the thesis itself and the master poster can be found here.  

---
### Abstract:
Especially in regulated industries, linear models continue to enjoy great popularity. They have been tried and tested in practice and the regulatory authorities are familiar with their interpretation. Despite years of experience with these models, the developers are often not able to achieve the performance of modern machine learning methods like treebased ensembles or neural networks.  
The introduction of the General Data Protection Regulation (GDPR) enhances the need for explainable and trustworthy machine learning methods. The aim is to develop a model with the highest possible prediction quality, that can provide the highest possible level of explainability. However, both requirements are diametrically opposed - at least for many problems. In the meantime, numerous methods have been developed to post-hoc explain the decisions of a black box model. These methods allow deep insights into the behaviour of the models, but cannot be compared with intrinsically explainable methods like logistic regression in terms of their interpretability.  
In this thesis two approaches are presented to combine the better predictive power of the modern, highly complex models with the explainable character of a logistic regression. These approaches implement a performance-oriented feature engineering for white-box models using the explanations of a more powerful black box approach. For this purpose, two different methods are developed, which can be applied independently or together. Depending on the methodology and the problem, these either increase the performance of the explainable model or its explainability. In some cases even both is possible.   
	The first methodology makes use of the structural differences between white-box and black-box methods with regard to the functional form of the resulting models. This indicates that transformations of the feature space are derived which maintain the explanatability of the model. The second method only considers observations if the black box model comes to a different prediction than the white box model.   
	By applying both methods, the performance of a logistic regression can be increased by 1.5 percentage points by SHAP explanations of a gradient boosted machine on an example data set. This reduces the difference between the ROC-AUC of the black box model and the logistic regression by 68 percent.
